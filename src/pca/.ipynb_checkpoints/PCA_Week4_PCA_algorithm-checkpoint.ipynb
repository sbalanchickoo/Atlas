{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACKAGE: DO NOT EDIT THIS CELL\n",
    "import numpy as np\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0f0931cbc4da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minteract\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mload_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mMNIST\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'load_data'"
     ]
    }
   ],
   "source": [
    "# PACKAGE: DO NOT EDIT THIS CELL\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from ipywidgets import interact\n",
    "\n",
    "from load_data import load_mnist\n",
    "\n",
    "MNIST = load_mnist()\n",
    "images, labels = MNIST['data'], MNIST['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "\n",
    "def normalize(X):\n",
    "    \"\"\"Normalize the given dataset X\n",
    "    Args:\n",
    "        X: ndarray, dataset\n",
    "    \n",
    "    Returns:\n",
    "        (Xbar, mean, std): tuple of ndarray, Xbar is the normalized dataset\n",
    "        with mean 0 and standard deviation 1; mean and std are the \n",
    "        mean and standard deviation respectively.\n",
    "    \n",
    "    Note:\n",
    "        You will encounter dimensions where the standard deviation is\n",
    "        zero, for those when you do normalization the normalized data\n",
    "        will be NaN. Handle this by setting using `std = 1` for those \n",
    "        dimensions when doing normalization.\n",
    "    \"\"\"\n",
    "    # mu = np.mean(X) zeros(X.shape[1]) # <-- EDIT THIS, compute the mean of X\n",
    "    mu = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    std_filled = std.copy()\n",
    "    std_filled[std==0] = 1.\n",
    "    Xbar = (X-mu)/std_filled                  # <-- EDIT THIS, compute the normalized data Xbar\n",
    "    return Xbar, mu, std\n",
    "\n",
    "def eig(S):\n",
    "    \"\"\"Compute the eigenvalues and corresponding eigenvectors \n",
    "        for the covariance matrix S.\n",
    "    Args:\n",
    "        S: ndarray, covariance matrix\n",
    "    \n",
    "    Returns:\n",
    "        (eigvals, eigvecs): ndarray, the eigenvalues and eigenvectors\n",
    "\n",
    "    Note:\n",
    "        the eigenvals and eigenvecs should be sorted in descending\n",
    "        order of the eigen values\n",
    "    \"\"\"\n",
    "    eigvals, eigvecs = np.linalg.eig(S)\n",
    "    eigvals_sorted_indices = np.argsort(np.array(eigvals))[::-1]\n",
    "    sorted_eigvecs = np.zeros(eigvecs.shape)\n",
    "    sorted_eigvals = sorted(eigvals, reverse=True)\n",
    "    \n",
    "    for i in range(r):\n",
    "        sorted_eigvecs[:,i] = eigvecs[:,eigvals_sorted_indices[i]]\n",
    "    \n",
    "    # return (None, None) # <-- EDIT THIS to return the eigenvalues and corresponding eigenvectors\n",
    "    return (sorted_eigvals, sorted_eigvecs)\n",
    "\n",
    "def projection_matrix(B):\n",
    "    \"\"\"Compute the projection matrix onto the space spanned by `B`\n",
    "    Args:\n",
    "        B: ndarray of dimension (D, M), the basis for the subspace\n",
    "    \n",
    "    Returns:\n",
    "        P: the projection matrix\n",
    "    \"\"\"\n",
    "    P = B @ np.linalg.inv(B.T @ B) @ B.T\n",
    "    return P #np.eye(B.shape[0]) # <-- EDIT THIS to compute the projection matrix\n",
    "\n",
    "def PCA(X, num_components):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X: ndarray of size (N, D), where D is the dimension of the data,\n",
    "           and N is the number of datapoints\n",
    "        num_components: the number of principal components to use.\n",
    "    Returns:\n",
    "        X_reconstruct: ndarray of the reconstruction\n",
    "        of X from the first `num_components` principal components.\n",
    "    \"\"\"\n",
    "    # your solution should take advantage of the functions you have implemented above.\n",
    "    Xbar = normalize(X)\n",
    "    cov = np.cov(Xbar)\n",
    "    sorted_eigvals, sorted_eigvecs = eig(cov)\n",
    "    \n",
    "    ev = np.zeros(sorted_eigvecs.shape)\n",
    "    for i in range(num_components):\n",
    "        ev[:,i] = sorted_eigvecs[:,i]\n",
    "\n",
    "    #projection and reconstruction\n",
    "    pr= Xbar.T @ ev.T #np.dot(Xbar.T,eigvecs.T) # (M N) * (N k) => (M k)\n",
    "    rec= ev.T @ pr.T  #np.dot(eigvecs.T, pr.T) #(N k) * (k M) => (N M)\n",
    "\n",
    "    return rec\n",
    "    # return X # <-- EDIT THIS to return the reconstruction of X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3], [2,1,2], [3,4,9]])\n",
    "mu = np.mean(a, axis=0)\n",
    "std = np.std(a, axis=0)\n",
    "std_filled = std.copy()\n",
    "std_filled[std==0] = 1.\n",
    "Xbar = (a-mu)/std_filled\n",
    "cov = np.cov(Xbar)\n",
    "\n",
    "Xbar_f, mu_f, std_f\n",
    "np.testing.assert_almost_equal(Xbar, normalize(a))\n",
    "\n",
    "eigvals, eigvecs = np.linalg.eig(cov)\n",
    "eigvals_sorted_indices = np.argsort(np.array(eigvals))[::-1]\n",
    "r, c = eigvecs.shape\n",
    "sorted_eigvecs = np.zeros(eigvecs.shape)\n",
    "for i in range(r):\n",
    "    sorted_eigvecs[:,i] = eigvecs[:,eigvals_sorted_indices[i]]\n",
    "\n",
    "sorted_eigvals = sorted(eigvals, reverse=True)\n",
    "B = sorted_eigvecs\n",
    "P = B @ np.linalg.inv(B.T @ B) @ B.T\n",
    "Z = P @ P.T @ (Xbar.T)\n",
    "Z *= std_filled\n",
    "Z += mu\n",
    "\n",
    "# print('X')\n",
    "# print(a)\n",
    "\n",
    "# print('\\nX_normalized: ')\n",
    "# print(Xbar)    \n",
    "\n",
    "# print('\\nmu')\n",
    "# print(mu)\n",
    "\n",
    "# print('\\nstd')\n",
    "# print(std)\n",
    "\n",
    "print('\\ncov')\n",
    "print(cov)\n",
    "print(np.cov(a))\n",
    "\n",
    "# print('\\neigvals')\n",
    "# print(eigvals)\n",
    "\n",
    "# print('\\neigvals sorted indices')\n",
    "# print(eigvals_sorted_indices)\n",
    "\n",
    "# print('\\neigvecs')\n",
    "# print(eigvecs)\n",
    "\n",
    "# print('\\nsorted eigvecs')\n",
    "# print(sorted_eigvecs)\n",
    "\n",
    "# print('\\nsorted eigvals')\n",
    "# print(sorted_eigvals)\n",
    "\n",
    "# print('\\nProjection matrix')\n",
    "# print(P)\n",
    "\n",
    "# k=3\n",
    "# idx = eigvals.argsort()[-k:][::-1]\n",
    "# print(idx)\n",
    "\n",
    "# eigvals1 = eigvals[idx] # k long \n",
    "# eigvecs1 = eigvecs[:,idx] # N x k\n",
    "\n",
    "# ev = np.zeros(eigvecs.shape)\n",
    "# for i in range(k):\n",
    "#     ev[:,i] = eigvecs[:,eigvals_sorted_indices[i]]\n",
    "\n",
    "# print(eigvecs1)\n",
    "# print(sorted_eigvecs)\n",
    "# print(eigvals.shape)\n",
    "# print(eigvecs.shape)\n",
    "# print(Xbar.shape)\n",
    "# print(eigvals)\n",
    "# print(eigvecs)\n",
    "\n",
    "#projection and reconstruction\n",
    "# pr= Xbar.T@ ev.T #np.dot(Xbar.T,eigvecs.T) # (M N) * (N k) => (M k)\n",
    "# rec= ev.T @ pr.T  #np.dot(eigvecs.T, pr.T) #(N k) * (k M) => (N M)\n",
    "# # # print (data-rec) # test reconstruction error\n",
    "\n",
    "# print('\\nPCA')\n",
    "# print(rec)\n",
    "\n",
    "# # # for num_component in range(1, 3):\n",
    "# from sklearn.decomposition import PCA as SKPCA\n",
    "# pca = SKPCA(n_components=k, svd_solver='full')\n",
    "# sklearn_reconst = pca.inverse_transform(pca.fit_transform(Xbar))\n",
    "# print('\\nreconstruction')\n",
    "# print(sklearn_reconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_component in range(1, 20):\n",
    "    from sklearn.decomposition import PCA as SKPCA\n",
    "    # We can compute a standard solution given by scikit-learn's implementation of PCA\n",
    "    pca = SKPCA(n_components=num_component, svd_solver='full')\n",
    "    sklearn_reconst = pca.inverse_transform(pca.fit_transform(Xbar))\n",
    "    reconst = PCA(Xbar, num_component)\n",
    "    #np.testing.assert_almost_equal(reconst, sklearn_reconst)\n",
    "#     print(np.square(reconst - sklearn_reconst).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
