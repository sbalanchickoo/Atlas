{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents <a id=\"0\"></a>\n",
    "* [Imports](#imports)\n",
    "* [Select modules](#select-modules)\n",
    "* [Define models](#define-models)\n",
    "* [Select models](#select-models)\n",
    "* [Cross validation](#cross-validation)\n",
    "* [Fit and predict test](#fit-and-predict-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "__print__ = print\n",
    "def print(string):\n",
    "    os.system(f'echo \\\"{string}\\\"')\n",
    "    __print__(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os, gc, time, joblib\n",
    "import numpy as np, pandas as pd\n",
    "import ashrae_scripts as scp\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Utilities\n",
    "from sklearn.metrics import accuracy_score, mean_squared_log_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "dir = !ls -a\n",
    "dir = !dir /b\n",
    "output_compression_type = 'gzip'\n",
    "if ('kernel-metadata.json' in dir):\n",
    "    # Local environment\n",
    "    src = 'Local'\n",
    "    compression_type = 'gzip'\n",
    "    data_folder = '../../../data/'\n",
    "    output_folder = '../../../data/'\n",
    "    df_path = data_folder + 'ashrae-train-test-1-0/df_label_enc.csv.gz'\n",
    "    df_test_path = data_folder + 'ashrae-train-test-1-0/df_test_label_enc.csv.gz'\n",
    "else:\n",
    "    # Kaggle environment\n",
    "    src = 'Kaggle'\n",
    "    compression_type = None\n",
    "    data_folder = '../input/'\n",
    "    output_folder = ''\n",
    "    df_path = data_folder + 'ashrae-train-test-1-0/df_label_enc.csv.gz'\n",
    "    df_test_path = data_folder + 'ashrae-train-test-1-0/df_test_label_enc.csv.gz'\n",
    "       \n",
    "print('Environment set to [{env}]'.format(env=src))\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select modules <a id=\"select-modules\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgbm = False\n",
    "perform_cross_validation = True\n",
    "predict_train = True\n",
    "predict_test = False\n",
    "generate_output = False\n",
    "\n",
    "debug = True\n",
    "scikit = True\n",
    "if debug:\n",
    "    rows = 1000000\n",
    "    rounds = 20000\n",
    "    stopping_rounds = 50\n",
    "else:\n",
    "    rows = None\n",
    "    rounds = 20000\n",
    "    stopping_rounds = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = [{'col_name': 'building_id', 'data_type': 'int16', 'feature_col': 1}\n",
    "         , {'col_name': 'meter', 'data_type': 'int8', 'feature_col': 1}\n",
    "         , {'col_name': 'site_id', 'data_type': 'int8', 'feature_col': 1}\n",
    "         , {'col_name': 'primary_use', 'data_type': 'int8', 'feature_col': 1}\n",
    "         , {'col_name': 'year_built', 'data_type': 'int16', 'feature_col': 1}\n",
    "         , {'col_name': 'floor_count', 'data_type': 'int8', 'feature_col': 1}\n",
    "         , {'col_name': 'air_temperature', 'data_type': 'float16', 'feature_col': 1}\n",
    "         , {'col_name': 'cloud_coverage', 'data_type': 'float16', 'feature_col': 1}\n",
    "         , {'col_name': 'dew_temperature', 'data_type': 'float16', 'feature_col': 1}\n",
    "         , {'col_name': 'precip_depth_1_hr', 'data_type': 'float16', 'feature_col': 1}\n",
    "         , {'col_name': 'sea_level_pressure', 'data_type': 'float16', 'feature_col': 1}\n",
    "         , {'col_name': 'wind_direction', 'data_type': 'float16', 'feature_col': 1}\n",
    "         , {'col_name': 'wind_speed', 'data_type': 'float16', 'feature_col': 1}\n",
    "         , {'col_name': 'meter_reading', 'data_type': 'float16', 'feature_col': 0}\n",
    "         , {'col_name': 'square_feet', 'data_type': 'float64', 'feature_col': 1}\n",
    "         , {'col_name': 'month', 'data_type': 'int8', 'feature_col': 1}\n",
    "         , {'col_name': 'day', 'data_type': 'int8', 'feature_col': 1}\n",
    "         , {'col_name': 'hour', 'data_type': 'int8', 'feature_col': 1}\n",
    "         , {'col_name': 'day_of_week', 'data_type': 'int8', 'feature_col': 1}\n",
    "         , {'col_name': 'weekend', 'data_type': 'int8', 'feature_col': 1}\n",
    "         , {'col_name': 'night', 'data_type': 'int8', 'feature_col': 1}\n",
    "         ]\n",
    "dtype = {col['col_name']: col['data_type'] for col in dtypes}\n",
    "df = pd.read_csv(df_path\n",
    "                 , dtype=dtype\n",
    "                 , parse_dates=['timestamp']\n",
    "                 , nrows=rows)\n",
    "df.drop(df[df['meter_reading']==np.inf].index, axis=0, inplace=True)\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col['col_name'] for col in dtypes if col['feature_col']==1]\n",
    "target_col = 'meter_reading'\n",
    "min_val = df[target_col].min()\n",
    "max_val = df[target_col].max()\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "# X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not debug:\n",
    "    del df\n",
    "    gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_train:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "\n",
    "if not debug and not predict_test:\n",
    "    del X\n",
    "    del y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using scikit api\n",
    "if scikit:\n",
    "    def rmsle(y_true, y_pred):\n",
    "        y_pred = np.clip(y_pred, min_val, max_val)\n",
    "        return 'RMSLE', np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False\n",
    "# using native api\n",
    "else:\n",
    "    def rmsle(preds, train_data):\n",
    "        labels = train_data.get_label()\n",
    "        preds = np.clip(preds, min_val, max_val)\n",
    "        return 'RMSLE', np.sqrt(np.mean(np.power(np.log1p(preds) - np.log1p(labels), 2))), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scikit:\n",
    "    gbm = lgb.LGBMRegressor(metrics='rmsle'\n",
    "                        , learning_rate=0.05\n",
    "                        , objective='regression'\n",
    "                        , bagging_freq=5\n",
    "                        , feature_fraction=0.9\n",
    "                        , bagging_fraction=0.8\n",
    "                        , num_round=rounds\n",
    "                        , verbose=-1\n",
    "                        )\n",
    "    \n",
    "else:\n",
    "    params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metrics': 'rmsle',\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_lgbm:\n",
    "    if scikit:\n",
    "        gbm.fit(X_train, y_train\n",
    "                , eval_set=[(X_val, y_val)]\n",
    "                , eval_metric=rmsle\n",
    "                , early_stopping_rounds=stopping_rounds)\n",
    "        y_pred = gbm.predict(X_val)\n",
    "        y_pred = np.clip(y_pred, min_val, max_val)\n",
    "    else:\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_val = lgb.Dataset(X_val, y_val)\n",
    "        gbm = lgb.train(params=params\n",
    "                        , train_set=lgb_train\n",
    "                        , num_boost_round=num_round\n",
    "                        , valid_sets=lgb_val\n",
    "                        , feval=rmsle\n",
    "                        , early_stopping_rounds=stopping_rounds)\n",
    "        y_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "    y_pred = np.clip(y_pred, min_val, max_val)\n",
    "    rmsle = mean_squared_log_error(y_val, y_pred)**0.5\n",
    "    print('Root mean square log error: {:.2f}'.format(rmsle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models <a id=\"define-modules\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = LinearSVR(random_state=13)\n",
    "lasso = Lasso(normalize=True, random_state=13)\n",
    "rf = RandomForestRegressor(n_estimators=5, random_state=13)\n",
    "lr = LinearRegression(fit_intercept=False, normalize=True)\n",
    "gbm = lgb.LGBMRegressor(boosting_type='gbdt'\n",
    "                        , num_leaves=500\n",
    "                        , metrics='rmsle'\n",
    "                        , learning_rate=0.05\n",
    "                        , objective='regression'\n",
    "                        , bagging_freq=5\n",
    "                        , feature_fraction=0.9\n",
    "                        , bagging_fraction=0.8\n",
    "                        , num_round=rounds\n",
    "                        , verbose=-1\n",
    "                        , random_state=13\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select models <a id=\"select-models\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_reg = [(gbm, 'LightGBM', 0) #1.3\n",
    "            #, (svr, 'SVR', 1)\n",
    "            #, (rf, 'RandomForest', 0) #0.67\n",
    "            #, (lasso, 'Lasso', 1)\n",
    "            , (lr, 'LinearRegression', 0) #1.77\n",
    "           ]\n",
    "meta_reg = [(lasso, 'Lasso1', 1)] #1\n",
    "#meta_reg = [(rf, 'RandomForest', 1)] #0.69\n",
    "meta, meta_label, meta_cross_val=meta_reg[0]\n",
    "\n",
    "stack = StackingCVRegressor(regressors=[model for model, label, cross_val in base_reg]\n",
    "                            , meta_regressor=meta\n",
    "                            , use_features_in_secondary=True\n",
    "                            , random_state=13)\n",
    "stack_reg = [(stack, 'Stack', 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation <a id=\"cross-validation\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_cross_validation:\n",
    "    def rmsle_crossval(y_true, y_pred):\n",
    "        y_pred = np.clip(y_pred, min_val, max_val)\n",
    "        return np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2)))\n",
    "    \n",
    "    rmsle_scorer = make_scorer(rmsle_crossval, greater_is_better=False)\n",
    "    models = base_reg + stack_reg\n",
    "    #models = stack_reg\n",
    "    \n",
    "    for model, label, cross_val in models:\n",
    "        if cross_val == 1:\n",
    "            t1_start = time.perf_counter()\n",
    "            scores = (cross_val_score(model, X_train, y_train, cv=5\n",
    "                                      #, scoring='neg_mean_squared_error'\n",
    "                                      , scoring=rmsle_scorer\n",
    "                                      , verbose=0\n",
    "                                     )*-1)**0.5\n",
    "            print(\"Root mean squared log error score: %0.2f (+/- %0.2f) [%s]\" % (\n",
    "            scores.mean(), scores.std(), label))\n",
    "            t1_stop = time.perf_counter()\n",
    "            print('Elapsed time in minutes: {sec:.2f}\\n'.format(sec=(t1_stop-t1_start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_train:\n",
    "    stack.fit(X_train, y_train)\n",
    "    y_pred_stack = stack.predict(X_val)\n",
    "    y_pred_stack = np.clip(y_pred_stack, min_val, max_val)\n",
    "    rmsle = mean_squared_log_error(y_val, y_pred_stack)**0.5\n",
    "    print('Root mean square log error (stack): {:.2f}'.format(rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_test:\n",
    "    dtype = {col['col_name']: col['data_type'] for col in dtypes if col['feature_col']==1}\n",
    "    df_test = pd.read_csv(df_test_path\n",
    "                     , dtype=dtype\n",
    "                     , parse_dates=['timestamp']\n",
    "                     , nrows=rows)\n",
    "    #df_test = sc.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and predict test <a id=\"fit-and-predict-test\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_test:\n",
    "    sites = list(X['site_id'].unique())\n",
    "    outputs = pd.DataFrame()\n",
    "    \n",
    "    for site in sites:\n",
    "        t1_start = time.perf_counter()\n",
    "        print('Site [{site_no}] start...'.format(site_no=site))\n",
    "        stack = StackingCVRegressor(regressors=[model for model, label, cross_val in base_reg]\n",
    "                                    , meta_regressor=meta\n",
    "                                    , use_features_in_secondary=True\n",
    "                                    , random_state=13)\n",
    "        \n",
    "        site_index = list(X[X['site_id']==site].index)\n",
    "        X_stack = X.loc[site_index, :]\n",
    "        y_stack = y[site_index]\n",
    "        stack.fit(X_stack, y_stack)\n",
    "        if sum(df_test['site_id']==site) > 0:\n",
    "            pred_site = stack.predict(df_test.loc[df_test['site_id']==site, feature_cols])\n",
    "            pred_site = np.clip(pred_site, min_val, max_val) \n",
    "            output_site = pd.DataFrame({'row_id': df_test.loc[df_test['site_id']==site, ['row_id']]['row_id'],'meter_reading': pred_site})\n",
    "            outputs = outputs.append(output_site, ignore_index = True)\n",
    "        print('Site [{site_no}] end!'.format(site_no=site))\n",
    "        t1_stop = time.perf_counter()\n",
    "        print('Elapsed time in minutes: {sec:.2f}'.format(sec=(t1_stop-t1_start)/60))\n",
    "    y_pred = outputs[target_col]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not debug and predict_test:\n",
    "    del X\n",
    "    del y\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_test:\n",
    "    del df_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_output:\n",
    "    outputs.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
