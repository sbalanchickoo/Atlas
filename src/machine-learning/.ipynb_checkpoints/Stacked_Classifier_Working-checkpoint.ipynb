{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# Any results you write to the current directory are saved as output.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Utilities\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification data    \n",
    "# Local environment\n",
    "#data_path = '../../data/learn-together'\n",
    "\n",
    "# Kaggle\n",
    "data_path = '../input/learn-together'\n",
    "\n",
    "df_test = pd.read_csv(data_path + '/test.csv')\n",
    "df_sample_submission = pd.read_csv(data_path + '/sample_submission.csv')\n",
    "df = pd.read_csv(data_path + '/train.csv')\n",
    "\n",
    "target = 'Cover_Type'\n",
    "features = list(df.columns)\n",
    "features.remove(target)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Base (level 0) and Stacking (level 1) estimators\n",
    "base_models = [\n",
    "                AdaBoostClassifier(random_state=5)\n",
    "                , RandomForestClassifier(n_estimators=100, random_state=5)\n",
    "                , KNeighborsClassifier()\n",
    "                , XGBClassifier(random_state=5)\n",
    "                , SVC(probability=True, random_state=5, gamma='scale')\n",
    "              ]\n",
    "            \n",
    "stack_model = RandomForestClassifier(n_estimators=600, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Base estimators separately\n",
    "#for model in base_models:\n",
    "    \n",
    "    # Fit model\n",
    "#    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "#    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "#    acc = accuracy_score(y_val, y_pred)\n",
    "#    print('{} Accuracy: {:.2f}%'.format(model.__class__.__name__, acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first level predictions (meta-features)\n",
    "def hold_out_predict(clf, X, y, cv):\n",
    "        \n",
    "    \"\"\"Performing cross validation hold out predictions for stacking\"\"\"\n",
    "    # Initilize\n",
    "    n_classes = len(np.unique(y)) # Assuming that training data contains all classes\n",
    "    meta_features = np.zeros((X.shape[0], n_classes)) \n",
    "    n_splits = cv.get_n_splits(X, y)\n",
    "    \n",
    "    # Loop over folds\n",
    "    print(\"Starting hold out prediction with {} splits for {}.\".format(n_splits, clf.__class__.__name__))\n",
    "    for train_idx, hold_out_idx in cv.split(X): \n",
    "        \n",
    "        # Split data\n",
    "        X_train = X.iloc[train_idx]    \n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_hold_out = X.iloc[hold_out_idx]\n",
    "\n",
    "        # Fit estimator to K-1 parts and predict on hold out part\n",
    "        est = copy.deepcopy(clf)\n",
    "        est.fit(X_train, y_train)\n",
    "        y_hold_out_pred = est.predict_proba(X_hold_out)\n",
    "        \n",
    "        # Fill in meta features\n",
    "        meta_features[hold_out_idx] = y_hold_out_pred\n",
    "\n",
    "    return meta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first level predictions (meta-features) from training data\n",
    "\n",
    "# Define 4-fold CV\n",
    "n_splits = 10\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Loop over classifier to produce meta features\n",
    "meta_train = pd.DataFrame()\n",
    "for model in base_models:\n",
    "    \n",
    "    # Create hold out predictions for a classifier\n",
    "    meta_train_model = hold_out_predict(model, X_train, y_train, kfold)\n",
    "    #print(pd.DataFrame(meta_train_model).head())\n",
    "    \n",
    "    # Gather meta training data\n",
    "    meta_train = pd.concat([meta_train, pd.DataFrame(meta_train_model)], axis=1)\n",
    "    #print(pd.DataFrame(meta_train).head())\n",
    "    \n",
    "#print(pd.DataFrame(meta_train).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Stacking Classifier\n",
    "\n",
    "# Set seed\n",
    "#if 'random_state' in stack_model.get_params().keys():\n",
    "#    stack_model.set_params(random_state=SEED)\n",
    "\n",
    "# Optional (Add original features to meta)\n",
    "#original_flag = False\n",
    "#if original_flag:\n",
    "#    meta_train = np.concatenate((meta_train, X_train), axis=1)\n",
    "#    meta_val = np.concatenate((meta_val, X_val), axis=1)\n",
    "\n",
    "# Fit model\n",
    "stack_model.fit(meta_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta-features for testing data\n",
    "meta_val = pd.DataFrame()\n",
    "for model in base_models:\n",
    "    \n",
    "    # Create hold out predictions for a classifier\n",
    "    model.fit(X_train, y_train)\n",
    "    meta_val_model = model.predict_proba(df_test)\n",
    "    \n",
    "    # Gather meta training data\n",
    "    meta_val = pd.concat([meta_val, pd.DataFrame(meta_val_model)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final output\n",
    "preds = stack_model.predict(meta_val)\n",
    "\n",
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': df_sample_submission.Id,\n",
    "                   'Cover_Type': preds})\n",
    "output.head()\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
