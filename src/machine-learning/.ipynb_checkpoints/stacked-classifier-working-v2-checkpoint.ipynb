{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = !ls -a\n",
    "if ('kernel-metadata.json' in dir):\n",
    "    src = 'Laptop'\n",
    "    # Local environment\n",
    "    data_path = '../../data/learn-together'\n",
    "else:\n",
    "    # Kaggle environment\n",
    "    src = 'Kaggle'\n",
    "    data_path = '../input'\n",
    "\n",
    "print('Environment set to [{env}]'.format(env=src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# Any results you write to the current directory are saved as output.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress future defaults warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# System imports\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Utilities\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df_test = pd.read_csv(data_path + '/test.csv')\n",
    "df_sample_submission = pd.read_csv(data_path + '/sample_submission.csv')\n",
    "df = pd.read_csv(data_path + '/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_correlation_features = []\n",
    "additional_feature_columns = []\n",
    "grid_search_n_splits = 5\n",
    "layer_one_folds = 2\n",
    "\n",
    "drop_singular_columns = 1\n",
    "get_feature_importances = 1\n",
    "generate_heatmap = 1\n",
    "drop_low_correlation_features = 1\n",
    "run_grid_search_for_base_estimators = 0\n",
    "\n",
    "generate_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with only 1 value, these are unlikely to be helpful\n",
    "if drop_singular_columns:\n",
    "    col_singular = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    print('Singular columns: {}'.format(col_singular))\n",
    "\n",
    "    # Drop singular columns\n",
    "    df.drop(col_singular, axis=1, inplace=True)\n",
    "    df_test.drop(col_singular, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_feature_importances:\n",
    "    target = 'Cover_Type'\n",
    "    features = list(df.columns)\n",
    "    features.remove(target)\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    bestfeatures = SelectKBest(k=10)\n",
    "    fit = bestfeatures.fit(X, y)\n",
    "    \n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    \n",
    "    # Concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score'] \n",
    "    print(featureScores.nlargest(20,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_feature_importances:\n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(X,y)\n",
    "    print(model.feature_importances_) \n",
    "    \n",
    "    # plot graph of feature importances for better visualization\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    feat_importances.nlargest(10).plot(kind='barh')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_heatmap:\n",
    "    # Get correlation to see if dimensionality can be reduced. \n",
    "    # Only considering non-categorical columns for simplicity\n",
    "    df_subset = df[['Elevation', 'Aspect', 'Slope',\n",
    "           'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "           'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
    "           'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n",
    "           'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n",
    "           'Wilderness_Area4', 'Cover_Type']]\n",
    "\n",
    "    corrmat = df_subset.corr()\n",
    "    top_corr_features = corrmat.index\n",
    "    plt.figure(figsize=(10,10))\n",
    "    g=sns.heatmap(df_subset[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop low correlation feature\n",
    "if drop_low_correlation_features:\n",
    "    df.drop(low_correlation_features, axis=1, inplace=True)\n",
    "    df_test.drop(low_correlation_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Cover_Type'\n",
    "features = list(df.columns)\n",
    "features.remove(target)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Base (level 0) and Stacking (level 1) estimators\n",
    "base_models = []\n",
    "\n",
    "model = {'model': AdaBoostClassifier(random_state=5)}\n",
    "parameters = {}\n",
    "model['parameters'] = parameters\n",
    "model['grid_search'] = 0\n",
    "base_models.append(model)\n",
    "\n",
    "model = {'model': SVC(probability=True, random_state=5, gamma='scale')}\n",
    "parameters = {}\n",
    "model['parameters'] = parameters\n",
    "model['grid_search'] = 0\n",
    "base_models.append(model)\n",
    "\n",
    "model = {'model': XGBClassifier(random_state=5)}\n",
    "parameters = {}\n",
    "model['parameters'] = parameters\n",
    "model['grid_search'] = 0\n",
    "base_models.append(model)\n",
    "\n",
    "model = {'model': RandomForestClassifier(n_estimators=100, random_state = 5)}\n",
    "parameters = {'n_estimators': [100, 150]}#, 200, 400, 600, 800, 1000, 1100]}\n",
    "model['parameters'] = parameters\n",
    "model['grid_search'] = 0\n",
    "base_models.append(model)\n",
    "\n",
    "model = {'model': KNeighborsClassifier()}\n",
    "parameters = {'n_neighbors': range(3,5,2),#12,2), \n",
    "              'weights': ['uniform', 'distance']}\n",
    "model['parameters'] = parameters\n",
    "model['grid_search'] = 0\n",
    "base_models.append(model)\n",
    "\n",
    "#model = {'model': LogisticRegression(random_state=5)}\n",
    "#parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "#model['parameters'] = parameters\n",
    "#model['grid_search'] = 1\n",
    "#base_models.append(model)\n",
    "\n",
    "# Define Stacking estimator\n",
    "stack_model = RandomForestClassifier(n_estimators=600, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Base estimators separately\n",
    "for base_model in base_models:\n",
    "    model = copy.deepcopy(base_model['model'])\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print('{} Accuracy: {:.2f}%'.format(model.__class__.__name__, acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do grid search on each base model\n",
    "if run_grid_search_for_base_estimators:\n",
    "    for base_model in base_models:\n",
    "        if base_model['grid_search']:\n",
    "            print('Model: {model_name}'.format(model_name=base_model['model'].__class__.__name__))\n",
    "            print('Optimizing parameters: [{params}]'.format(params=base_model['parameters']))\n",
    "            kfold = KFold(n_splits=grid_search_n_splits, shuffle=True)\n",
    "            CV = GridSearchCV(base_model['model']\n",
    "                          , param_grid=base_model['parameters']\n",
    "                          , scoring = 'accuracy'\n",
    "                          , n_jobs=-1\n",
    "                          , cv=kfold)\n",
    "            CV.fit(X_train, y_train)\n",
    "            best_model = CV.best_estimator_\n",
    "            base_model['best_model'] = best_model\n",
    "            print('Best score and parameter combination = ')\n",
    "            print(CV.best_score_)    \n",
    "            print(CV.best_params_) \n",
    "            print('\\n')\n",
    "\n",
    "for base_model in base_models:\n",
    "    if 'best_model'not in base_model:\n",
    "        base_model['best_model'] = base_model['model']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_grid_search_for_base_estimators:\n",
    "    for base_model in base_models:\n",
    "        if base_model['grid_search']:\n",
    "            model = copy.deepcopy(base_model['best_model'])\n",
    "            print('After grid search: ')\n",
    "            y_pred = model.predict(X_val)\n",
    "            acc = accuracy_score(y_val, y_pred)\n",
    "            print('{} Accuracy: {:.2f}%\\n'.format(model.__class__.__name__, acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first level predictions (meta-features)\n",
    "def hold_out_predict(clf, X, y, cv):\n",
    "        \n",
    "    \"\"\"Performing cross validation hold out predictions for stacking\"\"\"\n",
    "    # Initilize\n",
    "    n_classes = len(np.unique(y)) # Assuming that training data contains all classes\n",
    "    meta_features = np.zeros((X.shape[0], n_classes)) \n",
    "    n_splits = cv.get_n_splits(X, y)\n",
    "    \n",
    "    # Loop over folds\n",
    "    print(\"Starting hold out prediction with {} splits for {}.\".format(n_splits, clf.__class__.__name__))\n",
    "    for train_idx, hold_out_idx in cv.split(X): \n",
    "        \n",
    "        # Split data\n",
    "        X_train = X.iloc[train_idx]    \n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_hold_out = X.iloc[hold_out_idx]\n",
    "\n",
    "        # Fit estimator to K-1 parts and predict on hold out part\n",
    "        est = copy.deepcopy(clf)\n",
    "        est.fit(X_train, y_train)\n",
    "        y_hold_out_pred = est.predict_proba(X_hold_out)\n",
    "        \n",
    "        # Fill in meta features\n",
    "        meta_features[hold_out_idx] = y_hold_out_pred\n",
    "\n",
    "    return meta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first level predictions (meta-features) from training data\n",
    "\n",
    "# Define folds\n",
    "kfold = KFold(n_splits=layer_one_folds, shuffle=True)\n",
    "\n",
    "# Loop over classifier to produce meta features\n",
    "meta_train = pd.DataFrame()\n",
    "for base_model in base_models:\n",
    "    \n",
    "    model = copy.deepcopy(base_model['best_model'])\n",
    "    # Create hold out predictions for a classifier\n",
    "    meta_train_model = hold_out_predict(model, X_train, y_train, kfold)\n",
    "    #print(pd.DataFrame(meta_train_model).head())\n",
    "    \n",
    "    # Gather meta training data\n",
    "    meta_train = pd.concat([meta_train, pd.DataFrame(meta_train_model)], axis=1)\n",
    "    #print(pd.DataFrame(meta_train).head())\n",
    "\n",
    "stack_model.fit(meta_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta-features for testing data\n",
    "if generate_output:\n",
    "    meta_test = pd.DataFrame()\n",
    "    for base_model in base_models:\n",
    "        model = copy.deepcopy(base_model['best_model'])\n",
    "        \n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        meta_test_model = model.predict_proba(df_test)\n",
    "    \n",
    "        # Gather meta training data\n",
    "        meta_test = pd.concat([meta_test, pd.DataFrame(meta_test_model)], axis=1)\n",
    "    \n",
    "    # Final output\n",
    "    preds = stack_model.predict(meta_test)\n",
    "\n",
    "    # Save test predictions to file\n",
    "    output = pd.DataFrame({'Id': df_sample_submission.Id,\n",
    "                   'Cover_Type': preds})\n",
    "    output.head()\n",
    "    output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
