{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents <a id=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Imports](#imports)\n",
    "* [Block selection](#block-selection)\n",
    "* [Define models](#define-models)\n",
    "* [Identify Important Features](#identify-important-features)\n",
    "* [Feature engineering](#feature-engineering)\n",
    "* [Base estimators grid search](#base-estimators-grid-search)\n",
    "* [Stacking intro](#stacking-intro)\n",
    "* [Utility functions](#utility-functions)\n",
    "* [Determine best combination](#best-combination)\n",
    "* [Generate output](#generate-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports <a id=\"imports\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = !ls -a\n",
    "if ('kernel-metadata.json' in dir):\n",
    "    src = 'Laptop'\n",
    "    # Local environment\n",
    "    data_path = '../../data/learn-together'\n",
    "else:\n",
    "    # Kaggle environment\n",
    "    src = 'Kaggle'\n",
    "    data_path = '../input'\n",
    "\n",
    "print('Environment set to [{env}]'.format(env=src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# Any results you write to the current directory are saved as output.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Utilities\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Block selection <a id=\"block-selection\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_correlation_features = []\n",
    "additional_feature_columns = []\n",
    "grid_search_n_splits = 5\n",
    "layer_one_folds = 10\n",
    "\n",
    "get_feature_importances = 0\n",
    "drop_low_correlation_features = 0\n",
    "run_grid_search_for_base_estimators = 1\n",
    "determine_optimal_base_estimators_combination = 0\n",
    "\n",
    "generate_output = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define models <a id=\"define-models\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define level 1 estimators\n",
    "base_models = []\n",
    "\n",
    "model = {'model': RandomForestClassifier(random_state = 5)}\n",
    "parameters = {'n_estimators': [100, 150, 200, 400, 600, 800, 1000, 1100]}\n",
    "model['parameters'] = parameters\n",
    "model['grid_search'] = 1\n",
    "base_models.append(model)\n",
    "\n",
    "model = {'model': KNeighborsClassifier()}\n",
    "parameters = {'n_neighbors': range(3,12,2), \n",
    "              'weights': ['uniform', 'distance']}\n",
    "model['parameters'] = parameters\n",
    "model['grid_search'] = 1\n",
    "base_models.append(model)\n",
    "\n",
    "model = {'model': LogisticRegression(random_state=5)}\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "model['parameters'] = parameters\n",
    "model['grid_search'] = 1\n",
    "base_models.append(model)\n",
    "\n",
    "# Define Stacking estimator\n",
    "stack_model = RandomForestClassifier(n_estimators=600, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df_test = pd.read_csv(data_path + '/test.csv')\n",
    "df_sample_submission = pd.read_csv(data_path + '/sample_submission.csv')\n",
    "df = pd.read_csv(data_path + '/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify important features <a id=\"identify-important-features\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with only 1 value, these are unlikely to be helpful\n",
    "col_singular = [col for col in df.columns if df[col].nunique() == 1]\n",
    "print('Singular columns: {}'.format(col_singular))\n",
    "\n",
    "# Drop singular columns\n",
    "df.drop(col_singular, axis=1, inplace=True)\n",
    "df_test.drop(col_singular, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_feature_importances:\n",
    "    target = 'Cover_Type'\n",
    "    features = list(df.columns)\n",
    "    features.remove(target)\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    bestfeatures = SelectKBest(k=10)\n",
    "    fit = bestfeatures.fit(X, y)\n",
    "    \n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    \n",
    "    # Concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score'] \n",
    "    print(featureScores.nlargest(20,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_feature_importances:\n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(X,y)\n",
    "    print(model.feature_importances_) \n",
    "    \n",
    "    # plot graph of feature importances for better visualization\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    feat_importances.nlargest(10).plot(kind='barh')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correlation to see if dimensionality can be reduced. \n",
    "# Only considering non-categorical columns for simplicity\n",
    "df_subset = df[['Elevation', 'Aspect', 'Slope',\n",
    "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
    "       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n",
    "       'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n",
    "       'Wilderness_Area4', 'Cover_Type']]\n",
    "\n",
    "corrmat = df_subset.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(10,10))\n",
    "g=sns.heatmap(df_subset[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering <a id=\"feature-engineering\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop low correlation feature\n",
    "if drop_low_correlation_features:\n",
    "    df.drop(low_correlation_features, axis=1, inplace=True)\n",
    "    df_test.drop(low_correlation_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training and validation\n",
    "target = 'Cover_Type'\n",
    "features = list(df.columns)\n",
    "features.remove(target)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base estimators grid search <a id=\"base-estimators-grid-search\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do grid search on each base model\n",
    "optimum_base_models = []\n",
    "if run_grid_search_for_base_estimators:\n",
    "    for model in base_models:\n",
    "        if model['grid_search']:\n",
    "            print('Model: {model_name}'.format(model_name=model['model'].__class__.__name__))\n",
    "            print('Optimizing parameters: [{params}]'.format(params=model['parameters']))\n",
    "            kfold = KFold(n_splits=grid_search_n_splits, shuffle=True)\n",
    "            CV = GridSearchCV(model['model']\n",
    "                          , param_grid=model['parameters']\n",
    "                          , scoring = 'accuracy'\n",
    "                          , n_jobs=-1\n",
    "                          , cv=kfold)\n",
    "            CV.fit(X_train, y_train)\n",
    "            best_model = CV.best_estimator_\n",
    "            model['best_model'] = best_model\n",
    "            print('Best score and parameter combination = ')\n",
    "            print(CV.best_score_)    \n",
    "            print(CV.best_params_) \n",
    "\n",
    "for model in base_models:\n",
    "    if 'best_model'not in model:\n",
    "        model['best_model'] = model['model']\n",
    "    optimum_base_models.append(model['best_model'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get individual predictions\n",
    "print('Initial scores: ')\n",
    "for base_model in base_models:\n",
    "    model = base_model['model']\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print('{} Accuracy: {:.2f}%'.format(model.__class__.__name__, acc * 100))\n",
    "\n",
    "if run_grid_search_for_base_estimators:\n",
    "    print('\\nAfter grid search: \\n')\n",
    "    for model in optimum_base_models:\n",
    "        y_pred = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        print('{} Accuracy: {:.2f}%'.format(model.__class__.__name__, acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking intro <a id=\"stacking-intro\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 1\n",
    "1. Init\n",
    "  - Separate df (input) into features (X) and target (y)\n",
    "2. Layer 1, loop across folds\n",
    "  - Separate X and y into training and validation sets. Keep validation set aside and ignore for now\n",
    "  - For the first base model, split the training data into n folds\n",
    "  - Fit the base model on X_train, y_train from n-1 folds, and predict on the remaining nth fold. \n",
    "  - Add the predictions into a meta series for the base model\n",
    "3. Repeat (2), n times, each time with new nth fold. This will cover full training data. Will then end up with predictions for all n folds (full training data) in the meta seies (number of rows same as X_train)\n",
    "4. Loop across models\n",
    "  - Repeat (1), (2) and (3) for all base models\n",
    "  - Combine meta series for each base model into meta df - one column per base model, number of rows same as original training data. \n",
    "5. Optionally add an original feature from the training data into the meta dataframe\n",
    "6. This dataframe is feature data for next stage\n",
    "\n",
    "## Layer 2\n",
    "7. Fit the stacking model on the meta Dataframe (output of (6)) and y_train. This is our stacked model.\n",
    "\n",
    "## Validation\n",
    "8. Fit first base model on the full input data (X, y). Predict on X_val, this will generate a meta series\n",
    "9. Repeat (8) across each base model, combine output series from each base model to make meta dataframe for next layer\n",
    "10. Add the same feature column (as in (5)), from X_val into the meta dataframe from (9). This is source for next layer\n",
    "11. Predict using stacked model (output of (7)) on the output of (10)\n",
    "12. Compare prediction from (11) with y_val to get score\n",
    "\n",
    "## Testing\n",
    "13. Repeat steps (8), (9), (10), (11), this time using df_test in place of X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions <a id=\"utility-functions\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_base_models(model_list_in, X_in, y_in):\n",
    "    X_local = copy.deepcopy(X_in)\n",
    "    y_local = copy.deepcopy(y_in)\n",
    "    model_list = copy.deepcopy(model_list_in)\n",
    "    fitted_model_list = []\n",
    "    for model in model_list:\n",
    "        model.fit(X_local, y_local)\n",
    "        fitted_model_list.append(model)\n",
    "    return fitted_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_preds(fitted_model_list_in, X_in):\n",
    "    X_local = copy.deepcopy(X_in)\n",
    "    fitted_model_list = copy.deepcopy(fitted_model_list_in)\n",
    "    meta_df = pd.DataFrame()\n",
    "    for model in fitted_model_list:\n",
    "        y_local = model.predict(X_local)\n",
    "\n",
    "        y_local_df = pd.DataFrame(y_local, index=X_local.index)\n",
    "        meta_df[fitted_model_list.index(model)] = y_local_df[0]\n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_layer_one(base_model_list_in, stack_model_in, X_in, y_in, feature_columns):\n",
    "    X_local = copy.deepcopy(X_in)\n",
    "    y_local = copy.deepcopy(y_in)\n",
    "    model_list = copy.deepcopy(base_model_list_in)\n",
    "    stack_model_local = copy.deepcopy(stack_model_in)\n",
    "    \n",
    "    meta_df = pd.DataFrame()\n",
    "    kfold = KFold(n_splits=layer_one_folds, shuffle=True)\n",
    "    \n",
    "    # 4. Loop across models\n",
    "    for train_idx, hold_out_idx in kfold.split(X_local): \n",
    "        meta_fold = pd.DataFrame()\n",
    "        X_fold = X_local.iloc[train_idx]    \n",
    "        y_fold = y_local.iloc[train_idx]\n",
    "        X_hold_out_fold = X_local.iloc[hold_out_idx]\n",
    "        \n",
    "        train_fold_fitted_models = fit_base_models(model_list, X_fold, y_fold)\n",
    "        meta_fold  = get_meta_preds(train_fold_fitted_models, X_hold_out_fold)\n",
    "            \n",
    "        # Combine into meta df - one column per base model, number of rows same as original training data. \n",
    "        meta_df = pd.concat([meta_df, meta_fold])\n",
    "    #meta_df[feature_columns] = X_local[feature_columns]\n",
    "    stack_model_local.fit(meta_df, y_local)\n",
    "    #pred = stack_model_local.predict(X_val_in)\n",
    "    #score = accuracy_score(y_val_in, pred)\n",
    "    return stack_model_local\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine best combination of base models <a id=\"best-combination\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if determine_optimal_base_estimators_combination:\n",
    "    scores = []\n",
    "    for i in range(1, len(optimum_base_models)+1):\n",
    "        model_list_combinations += [list(m) for m in combinations(optimum_base_models, i)]\n",
    "\n",
    "    for model_list in model_list_combinations:\n",
    "        meta_df = get_fold_meta_from_layer_zero(optimum_base_models, X_train, y_train, feature_columns)\n",
    "        fitted_stack_model = stack_model.fit(meta_df, y_train)\n",
    "        y_val_pred = fitted_stack_model.predict(X_val)\n",
    "        score = accuracy_score(y_val, y_val_pred)\n",
    "        \n",
    "        comparison = {'score': score, 'model_list': model_list, 'layer_two_model': fitted_stack_model, 'feature_columns': feature_columns}\n",
    "        scores.append(comparison)\n",
    "    \n",
    "    for model_score in sorted(scores, key = lambda x: x['score'], reverse=True):\n",
    "        models = []\n",
    "        for model in model_score['model_list']:\n",
    "            model_short = model.__class__.__name__\n",
    "            models.append(model_short)\n",
    "        print('Models: \\n{models}\\nScore: {score}\\nTotal Columns: {columns}\\n'.format(models=models, score=model_score['score'], columns=model_score['total_columns']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_stack_model = process_layer_one(optimum_base_models, stack_model\n",
    "                                              , X_train\n",
    "                                              , y_train\n",
    "                                              , additional_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate output <a id=\"generate-output\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Fit each base model on the test data, this will generate a meta series\n",
    "if generate_output:\n",
    "    fitted_base_models = fit_base_models(optimum_base_models, X, y)\n",
    "    test_meta  = get_meta_preds(fitted_base_models, df_test)\n",
    "    #test_meta[additional_feature_columns] = df_test[additional_feature_columns]\n",
    "    test_pred = fitted_stack_model.predict(test_meta)\n",
    "\n",
    "    # Final output\n",
    "    # Save test predictions to file\n",
    "    output = pd.DataFrame({'Id': df_sample_submission.Id,\n",
    "                       'Cover_Type': test_pred})\n",
    "    output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
