{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "accessory-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "complicated-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of files\n",
    "PATH = 'D:\\\\MyDocuments\\\\Statements\\\\HSBC\\\\'\n",
    "result = [os.path.join(dp, f)\n",
    "          for dp, dn, filenames in os.walk(PATH) \n",
    "          for f in filenames \n",
    "          if (os.path.splitext(f)[1] == '.csv') and ('_processed' not in os.path.splitext(f)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "artificial-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df_param):\n",
    "    df = copy.deepcopy(df_param)\n",
    "    header_cols = ['date', 'transaction_type', 'payee', 'outflow', 'inflow', 'balance']\n",
    "    \n",
    "    # set columns\n",
    "    df.columns = header_cols\n",
    "    \n",
    "    # transform date\n",
    "    df[['payee', 'outflow', 'inflow', 'balance']] = df[['payee', 'outflow', 'inflow', 'balance']].astype(str)\n",
    "    df['date'] = pd.to_datetime(\n",
    "        df['date'].str[:2] \n",
    "        + '-' \n",
    "        + df['date'].str[3:6] \n",
    "        + '-' \n",
    "        + '20' + df['date'].str[-2:]\n",
    "    )\n",
    "    \n",
    "    # remove unneeded columns\n",
    "    cols = ['date', 'payee', 'outflow', 'inflow', 'balance']\n",
    "    df = df[cols]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # change data types\n",
    "    df.loc[:, 'balance'] = df['balance'].str.replace(',', '')\n",
    "    df.loc[:, 'outflow'] = df['outflow'].str.replace(',', '')\n",
    "    df.loc[:, 'inflow'] = df['inflow'].str.replace(',', '')\n",
    "    df.loc[df['outflow'] == '.', 'outflow'] = 0.0\n",
    "    df = df.astype({'outflow': float, 'inflow': float, 'balance': float})\n",
    "    \n",
    "    df['outflow'].fillna(0, inplace=True)\n",
    "    df['inflow'].fillna(0, inplace=True)\n",
    "    df['balance'].fillna(0, inplace=True)\n",
    "    \n",
    "    # remove balance carried forward rows within dataset\n",
    "    df_temp = df.iloc[1:-1, :]\n",
    "    idx = df_temp.loc[df_temp['payee'].str.contains('(?i)balance'), :].index\n",
    "    df.drop(idx, inplace=True)\n",
    "    \n",
    "    # combine outflow and inflow into single amount column\n",
    "    df.loc[:, 'outflow'] = (df['outflow']*-1) + df['inflow']\n",
    "    df = df.rename(columns={'outflow': 'amount'})\n",
    "    cols = ['date', 'payee', 'amount', 'balance']\n",
    "    df = df[cols]\n",
    "    \n",
    "    # combine multi-line payees\n",
    "    for idx, row in df.iterrows():\n",
    "        if ((df.loc[idx, 'amount']==0.0) and (df.loc[idx, 'balance']==0.0)):\n",
    "            df.loc[idx+1, 'payee'] = df.loc[idx, 'payee'] + ' ' + df.loc[idx+1, 'payee']\n",
    "            df.loc[idx+1, 'date'] = df.loc[idx, 'date']\n",
    "    df.drop(df[(df['amount']==0.0) & (df['balance']==0.0)].index, inplace=True)\n",
    "    df['date'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    # validate transactions, by comparing balances\n",
    "    df_datewise = df.groupby('date').sum(['amount', 'balance'])\n",
    "    df_datewise.reset_index(inplace=True)\n",
    "    for idx, row in df_datewise.iterrows():\n",
    "        if idx <= len(df_datewise.index) - 2: \n",
    "            df_datewise.loc[idx+1, 'calculated_balance'] = df_datewise.loc[idx, 'balance'] + df_datewise.loc[idx+1, 'amount']\n",
    "            \n",
    "    df_datewise.loc[0, 'balanced'] = True\n",
    "    df_datewise.loc[abs(round(df_datewise['balance'], 2) - round(df_datewise['calculated_balance'], 2)) == 0, 'balanced'] = True\n",
    "    \n",
    "    # compare calculated balance with actual balance\n",
    "    x = len(df_p_d[df_p_d['balanced'] != True].index)\n",
    "    if x == 0:\n",
    "        valid = True\n",
    "    else:\n",
    "        valid = False\n",
    "    return df, df_datewise, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "southern-orange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-01-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-02-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-03-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-04-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-05-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-06-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-07-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-08-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-09-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-10-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-11-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2019\\2019-12-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-01-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-02-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-03-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-04-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-05-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-06-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-07-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-08-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-09-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-10-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-11-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2020\\2020-12-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2021\\2021-01-25_Statement.csv]\n",
      "File: [D:\\MyDocuments\\Statements\\HSBC\\2021\\2021-02-25_Statement.csv]\n"
     ]
    }
   ],
   "source": [
    "# validate files\n",
    "for f in result:\n",
    "    file_path = f\n",
    "    print('File: [{file}]'.format(file = file_path))\n",
    "    df_in = pd.read_csv(file_path, header=None)\n",
    "    df, df_datewise, valid = process_df(df_in)\n",
    "    if not valid:\n",
    "        print('Valid: [{valid}]'.format(valid = valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "assumed-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process csv files\n",
    "for f in result:\n",
    "    file_path = f\n",
    "    df_in = pd.read_csv(file_path, header=None)\n",
    "    df, df_datewise, valid = process_df(df_in)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    processed_filename = os.path.splitext(file_name)[0] + '_processed.csv'\n",
    "    processed_full_path = os.path.join(os.path.dirname(file_path), 'processed', processed_filename)\n",
    "    df.to_csv(processed_full_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "chief-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of processed files\n",
    "result_ynab = [os.path.join(dp, f)\n",
    "               for dp, dn, filenames in os.walk(PATH) \n",
    "              for f in filenames \n",
    "              if (os.path.splitext(f)[1] == '.csv') and ('_processed' in os.path.splitext(f)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "prompt-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_payee(in_str: str) -> (str, str):\n",
    "    out_str = in_str\n",
    "    category = \"\"\n",
    "    mapping = [{\"str\": 'asda', 'repl': 'Asda', 'category': 'Basics: Groceries'}\n",
    "               , {\"str\": 'tesco', 'repl': 'Tesco', 'category': 'Basics: Groceries'}\n",
    "               , {\"str\": 'sainsburys', 'repl': 'Sainsburys', 'category': 'Basics: Groceries'}\n",
    "               , {\"str\": 'morrisons', 'repl': 'Morrisons', 'category': 'Basics: Groceries'}\n",
    "               , {\"str\": 'dominos', 'repl': 'Dominos', 'category': 'Discretionary: Entertainment'}\n",
    "               , {\"str\": 'papa johns', 'repl': 'Papa Johns', 'category': 'Discretionary: Entertainment'}\n",
    "               , {\"str\": 'just-eat', 'repl': 'Just Eat', 'category': 'Discretionary: Entertainment'}\n",
    "               , {\"str\": 'just-eat', 'repl': 'Just Eat', 'category': 'Discretionary: Entertainment'}\n",
    "               , {\"str\": 'netflix', 'repl': 'Netflix', 'category': 'Monthly: Streaming'}\n",
    "               , {\"str\": 'amazonprime', 'repl': 'Amazon Prime', 'category': 'Monthly: Streaming'}\n",
    "               , {\"str\": 'amazon prime', 'repl': 'Amazon Prime', 'category': 'Monthly: Streaming'}\n",
    "               , {\"str\": 'amazon.co.uk', 'repl': 'Amazon', 'category': 'Discretionary: Misc Purchases'}\n",
    "               , {\"str\": 'ee limited', 'repl': 'EE Limited', 'category': 'Basics: Phone'}\n",
    "               , {\"str\": 'the gym ltd', 'repl': 'The Gym Ltd', 'category': 'Monthly: Gym'}\n",
    "               , {\"str\": 's j p fish', 'repl': in_str, 'category': 'Basics: Rent'}\n",
    "              ]\n",
    "    for search_string in mapping:\n",
    "        if search_string['str'] in in_str.lower():\n",
    "            out_str = search_string['repl']\n",
    "            category = search_string['category']\n",
    "        \n",
    "    if 'pizza' in in_str.lower() and 'hut' in in_str.lower():\n",
    "        out_str = 'Pizza Hut'\n",
    "        category = 'Discretionary: Entertainment'\n",
    "    elif 'papa' in in_str.lower() and 'john' in in_str.lower():\n",
    "        out_str = 'Papa Johns'\n",
    "        category = 'Discretionary: Entertainment'\n",
    "        \n",
    "    return out_str, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "electronic-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ynab(df_param):\n",
    "    df_ynab = copy.deepcopy(df_param)\n",
    "    \n",
    "    # rename columns\n",
    "    df_ynab = df_ynab.rename(columns={'date': 'Date', 'payee': 'Payee'})\n",
    "    df_ynab['Date'] = pd.to_datetime(df_ynab['Date'])\n",
    "    \n",
    "    # remove balance rows\n",
    "    idx = df_ynab.loc[df_ynab['Payee'].str.contains('(?i)balance'), :].index\n",
    "    df_ynab.drop(idx, inplace=True)\n",
    "    \n",
    "    # create additional ynab columns, format values\n",
    "    df_ynab['Category'] = ''\n",
    "    df_ynab['Memo'] = ''\n",
    "    df_ynab.loc[df_ynab['amount'] < 0, 'Outflow'] = df_ynab['amount'] * -1\n",
    "    df_ynab.loc[df_ynab['amount'] > 0, 'Inflow'] = df_ynab['amount']\n",
    "    df_ynab['Outflow'].fillna('', inplace=True)\n",
    "    df_ynab['Inflow'].fillna('', inplace=True)\n",
    "    cols = ['Date', 'Payee', 'Category', 'Memo', 'Outflow', 'Inflow']\n",
    "    df_ynab = df_ynab[cols]\n",
    "    df_ynab['Date'] = df_ynab['Date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    # process payees\n",
    "    df_ynab[['Payee', 'Category']] = df_ynab['Payee'].apply(transform_payee).apply(pd.Series)\n",
    "    return df_ynab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "flying-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_payees = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "mature-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process processed csv files\n",
    "for f in result_ynab:\n",
    "    file_path = f\n",
    "    df_in = pd.read_csv(file_path)\n",
    "    df_ynab_out = process_ynab(df_in)\n",
    "    ynab_file_name = os.path.basename(file_path).replace('_processed', '_ynab')\n",
    "    ynab_dir_name = os.path.dirname(file_path).replace('processed', 'ynab')\n",
    "    ynab_full_path = os.path.join(ynab_dir_name, ynab_file_name)\n",
    "    df_ynab_out.to_csv(ynab_full_path, index=False)\n",
    "    \n",
    "    for payee in list(df_ynab_out['Payee']):\n",
    "        if payee not in known_payees:\n",
    "            known_payees.append(payee)\n",
    "            \n",
    "known_payees = list(set(known_payees))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
